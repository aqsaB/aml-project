{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f33369c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow import keras\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "tokenizer = Tokenizer(num_words = 8000, filters = '!\"#$%&()*+,-./:;<=>?@[\\\\]^`{|}~\\t\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fa70352-1e03-4f1c-921b-c3c27c615fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Disable all GPUS\n",
    "    tf.config.set_visible_devices([], 'GPU')\n",
    "    visible_devices = tf.config.get_visible_devices()\n",
    "    for device in visible_devices:\n",
    "        assert device.device_type != 'GPU'\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f738a454-fa09-4b5a-b3ca-46dd084d5084",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dev = []\n",
    "data_test = []\n",
    "data_train = []\n",
    "file_name_dev = \"audioDataDev.pickle\"\n",
    "file_name_test = \"audioDataTest.pickle\"\n",
    "file_name_train = \"audioDataTrain.pickle\"\n",
    "\n",
    "with (open(file_name_dev, \"rb\")) as f:\n",
    "    while True:\n",
    "        try:\n",
    "            data_dev.append(pickle.load(f))\n",
    "        except EOFError:\n",
    "            break\n",
    "f.close()\n",
    "\n",
    "with (open(file_name_test, \"rb\")) as f:\n",
    "    while True:\n",
    "        try:\n",
    "            data_test.append(pickle.load(f))\n",
    "        except EOFError:\n",
    "            break\n",
    "f.close()\n",
    "\n",
    "with (open(file_name_train, \"rb\")) as f:\n",
    "    while True:\n",
    "        try:\n",
    "            data_train.append(pickle.load(f))\n",
    "        except EOFError:\n",
    "            break\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36d52b8c-f03c-4c18-939f-407b1937a976",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = []\n",
    "y_dev = []\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for i in range(len(data_dev)-1):\n",
    "    X_dev.append(data_dev[i+1][4])\n",
    "for i in range(len(data_dev)-1):\n",
    "    y_dev.append(data_dev[i+1][6:12])\n",
    "    \n",
    "for i in range(len(data_test)-1):\n",
    "    X_test.append(data_test[i+1][4])\n",
    "for i in range(len(data_test)-1):\n",
    "    y_test.append(data_test[i+1][6:12])\n",
    "    \n",
    "for i in range(len(data_train)-1):\n",
    "    X_train.append(data_train[i+1][4])\n",
    "for i in range(len(data_train)-1):\n",
    "    y_train.append(data_train[i+1][6:12])\n",
    "\n",
    "X_dev = np.array(X_dev)\n",
    "y_dev = np.array(y_dev).astype(bool).astype(int)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test).astype(bool).astype(int)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train).astype(bool).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6484a2c1-2a7b-4a98-8122-7925264493e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0c7c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent(X, y):\n",
    "    data = []\n",
    "    for i in range(1, len(X)):\n",
    "        #add text\n",
    "        temp = X[i].split('\\n')\n",
    "        text_obj = temp[0][6:]\n",
    "\n",
    "        row = [text_obj, np.array(y[i])]\n",
    "        data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(data, columns = ['text', 'sentiment'])\n",
    "    return df\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    sw = stopwords.words('english')\n",
    "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def sequences(dframe):\n",
    "    tokenizer = Tokenizer(num_words = 8000, filters = '!\"#$%&()*+,-./:;<=>?@[\\\\]^`{|}~\\t\\n')\n",
    "    tokenizer.fit_on_texts(dframe['text'])\n",
    "    X = tokenizer.texts_to_sequences(dframe['text'].values)\n",
    "    y = dframe['sentiment'].values\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abd0d461-1007-4a33-ace5-f98c77bb7af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = sent(X_dev, y_dev)\n",
    "dev_df['text'] = dev_df['text'].apply(remove_punctuation).apply(remove_stopwords)\n",
    "dev = sequences(dev_df)\n",
    "\n",
    "test_df = sent(X_test, y_test)\n",
    "test_df['text'] = test_df['text'].apply(remove_punctuation).apply(remove_stopwords)\n",
    "test = sequences(test_df)\n",
    "\n",
    "train_df = sent(X_train, y_train)\n",
    "train_df['text'] = train_df['text'].apply(remove_punctuation).apply(remove_stopwords)\n",
    "train = sequences(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7bc7b54-fe14-4e75-9030-dbe07f43d91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev_text = pad_sequences(dev[0])\n",
    "y_dev_text = pad_sequences(dev[1])\n",
    "X_test_text = pad_sequences(test[0])\n",
    "y_test_text = pad_sequences(test[1])\n",
    "X_train_text = pad_sequences(train[0])\n",
    "y_train_text = pad_sequences(train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6012d63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = X_train_text.reshape(X_train_text.shape[0], 1, X_train_text.shape[1])\n",
    "X_test_text = X_test_text.reshape(X_test_text.shape[0], 1, X_test_text.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51f6f92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16326, 1, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52a25550",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Adam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#set up the LSTM model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#using the LSTM model with relu activation\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m adam \u001b[38;5;241m=\u001b[39m \u001b[43mAdam\u001b[49m(\u001b[38;5;241m0.0002\u001b[39m)\n\u001b[0;32m      6\u001b[0m lstm \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mSequential()\n\u001b[0;32m      7\u001b[0m lstm\u001b[38;5;241m.\u001b[39madd(LSTM(\u001b[38;5;241m32\u001b[39m, input_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m, X_train_text\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Adam' is not defined"
     ]
    }
   ],
   "source": [
    "#set up the LSTM model\n",
    "\n",
    "\n",
    "#using the LSTM model with relu activation\n",
    "adam = Adam(0.0002)\n",
    "lstm = keras.Sequential()\n",
    "lstm.add(LSTM(32, input_shape = (1, X_train_text.shape[2]), activation='relu', return_sequences=False))\n",
    "lstm.add(Dense(6))\n",
    "lstm.compile(loss='mean_squared_error',metrics='accuracy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee399911",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5988c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lstm.fit(X_train_text, y_train_text, epochs=30, batch_size=10, verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eedd77",
   "metadata": {},
   "source": [
    "loading testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06679452",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= lstm.predict(X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df0bf36-70fb-4eae-a679-cfe75c118c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.41\n",
    "yhat = np.where(y_pred > threshold, 1, 0)\n",
    "print(y_pred[1])\n",
    "print(y_test_text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da26262-4b33-4022-b310-89cf81ced022",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "total = 0\n",
    "similar = 0\n",
    "for i in range(len(y_test_text)):\n",
    "    for j in range(len(y_test_text[i])):\n",
    "        if y_test_text[i][j] == y_pred[i][j]:\n",
    "            similar += 1\n",
    "        total += 1\n",
    "acc = similar/total\n",
    "\n",
    "print('>%.3f' % acc)\n",
    "results.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2bc3db-9c91-4560-9cc9-f49e702b8d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_f = []\n",
    "y_hat_f = []\n",
    "for i in range(len(y_pred[0])):\n",
    "    y_temp_t = []\n",
    "    y_temp_h = []\n",
    "    for j in range(len(y_pred)):\n",
    "        y_temp_t.append(y_test_text[j][i])\n",
    "        y_temp_h.append(y_pred[j][i])\n",
    "    y_test_f.append(y_temp_t)\n",
    "    y_hat_f.append(y_temp_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0357c5f1-9ed9-49f1-9872-ec5fda209c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = ['Happy', 'Sad', 'Anger', 'Surprise', 'Disgust', 'Fear']\n",
    "\n",
    "\n",
    "for n, ax in zip(range(len(emotion)), axs.ravel()):\n",
    "    # add a new subplot iteratively\n",
    "    conf_matrix = confusion_matrix(y_true=y_test_f[n], y_pred=y_hat_f[n])\n",
    "    #\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "\n",
    "    # chart formatting\n",
    "    ax.set_title('${}$'.format(emotion[n]), fontsize=18)\n",
    "    ax.set_xlabel('Predictions', fontsize=18)\n",
    "    ax.set_ylabel('Actuals', fontsize=18)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50133567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"y1 MSE:%.4f\" % mean_squared_error(y_test_text[:,0], y_pred[:,0]))\n",
    "print(\"y2 MSE:%.4f\" % mean_squared_error(y_test_text[:,1], y_pred[:,1])) \n",
    "print(\"y3 MSE:%.4f\" % mean_squared_error(y_test_text[:,2], y_pred[:,2])) \n",
    "print(\"y4 MSE:%.4f\" % mean_squared_error(y_test_text[:,3], y_pred[:,3])) \n",
    "print(\"y5 MSE:%.4f\" % mean_squared_error(y_test_text[:,4], y_pred[:,4])) \n",
    "print(\"y6 MSE:%.4f\" % mean_squared_error(y_test_text[:,5], y_pred[:,5])) \n",
    "\n",
    "x_ax = range(len(X_test_text))\n",
    "plt.title(\"LSTM multi-output prediction\")\n",
    "plt.scatter(x_ax, y_test_text[:,0],  s=6, label=\"y1-test\")\n",
    "plt.plot(x_ax, y_pred[:,0], label=\"y1-pred\")\n",
    "plt.scatter(x_ax, y_test_text[:,1],  s=6, label=\"y2-test\")\n",
    "plt.plot(x_ax, y_pred[:,1], label=\"y2-pred\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f30f98f-c4df-45f3-8fdc-0ddbe6559b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, ax in zip(range(len(emotion)), axs.ravel()):\n",
    "    # add a new subplot iteratively\n",
    "    conf_matrix = confusion_matrix(y_true=y_test_f[n], y_pred=y_hat_f[n])\n",
    "    #\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "\n",
    "    # chart formatting\n",
    "    ax.set_title('${}$'.format(emotion[n]), fontsize=18)\n",
    "    ax.set_xlabel('Predictions', fontsize=18)\n",
    "    ax.set_ylabel('Actuals', fontsize=18)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b547da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "range_vals = [i/100 for i in range(1, 30)]\n",
    "\n",
    "\n",
    "precision = []\n",
    "recall = []\n",
    "accuracy = []\n",
    "for i in range_vals:\n",
    "    precision.append(precision_score(y_test_text[1], y_pred[1]))\n",
    "    recall.append(recall_score(y_test_text[1], y_pred[1]))\n",
    "    accuracy.append(accuracy_score(y_test_text[1], y_pred[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1716a82b-f38f-4675-9480-5f1cbc489e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566ff197-6404-4ad4-99fc-663105e51f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (11, 7))\n",
    "sns.lineplot(range_vals, precision)\n",
    "sns.scatterplot(range_vals, precision)\n",
    "sns.lineplot(range_vals, recall)\n",
    "sns.scatterplot(range_vals, recall)\n",
    "sns.lineplot(range_vals, accuracy)\n",
    "sns.scatterplot(range_vals, accuracy)\n",
    "plt.legend(['prec', 'rec', 'Acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d018b75-ce50-422f-9e36-a8a88a2e7684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
